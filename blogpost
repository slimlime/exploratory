## 24/8/2017

At first I decided that an 'object model' was unnecessary. I would model everything with bits of state and if statements. In the test game there is a key buried in a crack in the floor which cannot be seen. You can take the key once you have performed the action which allows it to be seen. You can also examine it if you can see it. But.. you can also examine it if you are carrying it, that is if you have typed TAKE KEY. At the moment you can't drop it. Other things you can't do

- Disambiguate easily between that KEY and another 'KEY'
- Put it back in the crack
- Drop it somewhere else
- Examine it when you have dropped it elsewhere

So an object model really is required. I know that for the main game I will need to drop objects and also put them in places, e.g. DROP COIN IN WELL.

Physical objects have the idea of place, also, you have to be able to distinguish between different objects with the same names So I am going to model PLACE and OBJECT-ID. For practicalities sake, these will be bytes. I am not altogether confident that PLACE will fit into byte, but it is just a concept- if the implementation has to change later then so be it.

PLACE can be either a LOCATION or a SPECIAL LOCATION. A LOCATION is any of the game locations. Each LOCATION will be a PLACE. Each location will be assigned a PLACE. The special locations will be EGO and VOID. In memory there will be an array, where the index is the object ID and the value will be the PLACE. To determine whether an object is 'present' we can perform the check

(IF CURRENT-LOCATION==PLACE[ID] || PLACE[ID]==EGO)

To extend this, more places will be defined which correspond to objects that can carry other objects, e.g. bags. This is Yaggers at the moment as the implementation may be a bit tricky. I think that each object that could be considered a 'bag' would be added to the PLACE list first, along with the special locations so that each location id==place id(location). It would also be preferable to make (for the 'bag' objects at least) object-id==place-id. I am going to have to think about how practical this is (and I am not sure if it is possible).

So, every object has a place. Every place that an object can be is a byte. Every location is a place. The locations, EGO and VOID are places. Every object that can carry another object is a place such that PLACE-ID==OBJECT-ID.

Additionally, this array merely describes the location of the objects, not the behaviour. Generic behaviour must be defined for each object- it might have to be the case that we have OBJECT dispatch tables. This is essentially a v-table for each object, with an entry if and only if there is specialised behaviour relating to that object. For example,

TAKE MJOLNIR

would have an entry which checked for Thorness, whereas

TAKE APPLE

could probably be handled by the generic TAKE handler.

## 23/8/2017

Bye bye Hash table.

The hash table parsing code has been deleted in its entirety and replaced with a binary search based approach. This new approach only recognises words that it has in its dictionary, and does not mistake words it does not know (up to four characters).

So yet again I have learned the lesson of YAGNI the hard way.  It wasn't that it was the wrong decision to do it that way at first, it was the fact that I spent too much effort on getting it nice. Now all that effort has been wasted. It wouldn't have saved me from having to change it, but at least I would have saved all the time I spent making utilities, and doing the brute force search algorithm etc. I think what I will try next time I have an idea is making the Minimum Effort Solution that Actually works, that way if they survive the next round of re-factoring, there is less waste, and you can nicey them up at the end.

The end of the month is approaching, and while I have abandoned the idea that I can finish a full game for the IF competition deadline in September, my target is to have a complete mini-game consisting of three rooms. Left to do,

- Finish rooms 2 and 3
- Create object model (e.g. GET/DROP in places)
- Javascript emulator

There is a JS emulator online somewhere, so hopefully I can get it up on a site somewhere.

Further ideas

- Allow saving of state- this will be important for the competition.
  To do this, I may just UUENCODE the state and update the URL. This is a simple solution for users, thought it may be a bit tricky to ensure it works consistently.

- Keyboard input.
  I have decided there is no point in doing a keyboard driver for fake hardware. I will provide a function which can be called to add a char/backspace which will trigger the emulator to execute it.


- C64 port
  This would be really nice, but I think I am going to wait until I have finished the full game and see the reaction to it before I do this as it could be significant effort.


## 3/7/2017 Esoteric Considerations

What is programming?

If one imagines a cross-section of the different programs in existence one will find that they all share some things in common. Namely, state and changes to state. Put alternatively, state and behaviour. Fundamentally I think this is what computation is all about. Database app, web-sites, games all take, manipulate and deliver state.

But what about pure functional languages? Surely they aren't about manipulating state? Absolutely they are. They do not exist in a vacuum- their state is the input provided to them and the output they give. Conceptually the sausage factory in the middle can be described as functions which have no side-effects but IMO this is a distinction without a difference. Functional concepts are absolutely essential in arranging ones thoughts about computation, but they are not fundamental to its implementation. Definite advantages can be had by thinking about a computational process in terms of pure function composition, but it is a category error to insist this be the basis for a *real* programming language.

Early programs (some of mine from the 80s for example) are a mess of state and gotos; they are basically impossible to fully understand. Programs such as this have a combinatorial explosion of state such that it is easy to get into the soup with no idea how it happened. The only solution is to turn it off and on again. Absolutely no-one who has experienced this wants to go back to it.

What I have learned programming this 6502 adventure game so far,

- Most bugs were in behaviour code- i.e. either incorrect design or just flat out incorrectly implemented logic.
- TWO 'state' bugs that went undetected. One was an uninitialised loop counter, the other was the parse input buffer not being cleared down. This is not indicative of a combinatorial explosion of dodgy state.
- Unit testing is good to ensure behaviour works
- Unit testing still can't deal with unknown state transitions

So,

- Functional thinking is useful *in the conceptual or design realm*. Make a serious effort to reduce the amount of state, and therefore the number of state transitions.
- Functional straitjackets *in the implementation realm* are not useful. Loop, modify state, do what needs to be done, get over it.

### Fetishization of recursion.

(UPDATE: There is a recursive thing in the binary tree parser- it was a nightmare, and it will need to be unpicked so that tree analysis can be done before conversion into code- for that to happen I will do it in a way that produces an explicit stack or tree structure)

Recursion is over-rated. There are *very* few problems which require recursion, for example, there is no recursion in the code-base for this adventure game. None. Scheme, Haskell (and most modern LISP) tutorials would have us believe that if we aren't doing recursion to add a list of numbers together then we are like the apes at the beginning of the 2001 movie, frantically bashing away at a mutable accumulator with a bone. LISP tutorials would be a whole lot more palatable to a wider subsection of the programming population *if* they didn't try to convert everyone to the mysteries of functionalism at the same time. That's not to say there isn't a place for it; there is, but LISP is complicated enough as it is  (and that's without considering the whole EMACS/SLIME dimension)

Do we need recursion?

Can you type a recursive solution faster than you can type a loop based solution? If so, do it. Did we *need* to do it recursively? No. Is it faster? Probably not, most languages don't have tail-call optimisation.

Ok, my language has tail-call optimisation (TCO). Great! You might even get it as a benefit of any JITting that occurs. Now, did you remember to put the recursive call in the tail position? Not sure? Is it even possible? If it's not possible, you may be able to do it as a loop- if not congratulations, you may need recursion!
 
Ok, we need recursion, we can't use TCO as this is a problem that requires some state to be saved until after the recursive call. Now, there is but one question. Do you have enough stack to solve the problem? No, make it two questions. Do you have enough stack to solve the problem *and* can you arrange the code so that it doesn't melt your brain? This is not an idle consideration. In my programming career I have written enough recursive code that really did need to store up the state, and the primary worry was whether it would scale. The secondary worry was arranging the functions just so, so that the shape of the call stack fit the shape of the problem. This was often a frustrating afternoon of re-arranging functions and prototypes etc which often left me with a tail-wagging-the-dog type feeling.

If the problem doesn't fit the shape of the call stack well, or if the call stack would not be large enough you may need to 'emulate' recursion by using some sort of queue, or explicit stack and... a loop. At this point I guarantee your code will not have the idiomatic shape of recursive code in your chosen language- all those pretty tutorials are for nothing.

Oh hell! Now my code isn't functional! How can I compose it and take advantage of all the gifts and boons this bestows? Just concentrate on make your top-leve function pure, if composing it and keeping it nice and modular is your concern. Don't worry about the seething mass of state inside, no-one else will ever see it.

Oh hell! Now my code isn't functional! How can I compose it with other behaviour INSIDE the recursive code. Have you ever tried to do this as a solution to anything outside a toy problem? I think there are probably five people in the world who can do this with ease and they are either working on the Haskell compiler or their PhD thesis is literally called "Mutually Recursive Functions for Fun and Recreation". Of course, for this thesis, they have written their own Scheme implementation in Python, and the recursive bits are transpiled to imperative code, just for now, until they can make it more performant.

Let us examine three Fibonaccis in SBCL LISP.

- Loop based
- Recursive
- Recursive, memoized

~~~~

CL-USER> (time (fibonacci-1 40))
Evaluation took:
  9.362 seconds of real time
  9.084000 seconds of total run time (9.068000 user, 0.016000 system)
  97.03% CPU
  12,148,887,044 processor cycles
  0 bytes consed
  
102334155
CL-USER> (time (fibonacci-2 40))
Evaluation took:
  0.000 seconds of real time
  0.000000 seconds of total run time (0.000000 user, 0.000000 system)
  100.00% CPU
  5,385 processor cycles
  0 bytes consed
  
102334155

~~~~

Guess which one is the recursive solution. Now, you may complain that the recursive solution is naive. But how precisely do you know this? In this case, it scales pretty badly and in a real world problem you would notice immediately that it is a bad idea. But lots of real world problems do not scale that badly, to begin with. There is a creeping sense of dread as the problem scales.. in production. Now you have a much larger problem. That's not to say you won't get scaling problems with an imperative solution; this definitely happens, but IMO it is a lot clearer in imperative code that, for example, you have an n^2 algorithm waiting to bite you. Plus, was it really worth the extra time and effort to arrange your code *just so*, that you are all nice and recursive.

Conclusion

Recursion is mostly useful for toy problems of the sort found in modern programming tutorials, but may find occasional use where the problem is well suited to being expressed recursively and has no scaling problems. Mutual recursion in anything more complex than working out Fibonacci is basically far too complex to arrange in practice. Sadly I think that LISP tutorials feature too much emphasis on mapcar and pals- a construct which is not very efficient. It makes more sense to instruct functional programming in C# using LINQ, but even there we see the limits of composability very quickly. Going beyond a few chained Selects and Wheres is a painful nightmare in practice. Grouping? Forget about it.

Now let us look at a recursive solution with memoization, which will lead us to the other thing that programming is.

- Recursion with memoization

(note to self, the other thing that the act of programming is- compression of state transformation. Since we are transforming state, all programming can be conceptualised as a big look up table- given this, produce this. Programming is the act of making this palatable to a real computer, such that it produces the answer before the end of time, and without using all the available matter in the universe to store your look-up table)

(Related to this idea is that programming is a creative endeavour, there are an infinite number of ways of taking an enormous state projection and producing a program to compress it)

## Programming is transformation of state

## Transformation of state is Data (de-)compression

## Data (de-)compression is prediction

## Prediction is closely related to action, which is transformation of state

And now we have arrived at either a profoundly strange loop, or a humdrum tautology.

